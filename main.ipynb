{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\19105\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\19105\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\19105\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\19105\\Documents\\githubPersonal\\Video Game Recommendation System\\main.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/19105/Documents/githubPersonal/Video%20Game%20Recommendation%20System/main.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m bxdf[[\u001b[39m'\u001b[39m\u001b[39mUser ID\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mISBN\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mBook-Rating\u001b[39m\u001b[39m'\u001b[39m]] \u001b[39m=\u001b[39m bxdf[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m;\u001b[39m\u001b[39m'\u001b[39m, expand\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\19105\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\19105\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "bxdf[['User ID', 'ISBN', 'Book-Rating']] = bxdf[0].str.split(';', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download and extraction completed successfully.\n",
      "Files have been extracted to 'data/raw/'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "\n",
    "def download_and_extract_zip(zip_url, target_directory):\n",
    "    try:\n",
    "        # Fetch the zip data from the URL\n",
    "        response = requests.get(zip_url)\n",
    "        response.raise_for_status()  # Raise an exception for 4xx or 5xx errors\n",
    "\n",
    "        # Create the target directory if it doesn't exist\n",
    "        if not os.path.exists(target_directory):\n",
    "            os.makedirs(target_directory)\n",
    "\n",
    "        # Load the zip data into a ZipFile object\n",
    "        with zipfile.ZipFile(io.BytesIO(response.content), 'r') as z:\n",
    "            # Extract all the files from the zip archive to the target directory\n",
    "            z.extractall(target_directory)\n",
    "\n",
    "        print(\"Download and extraction completed successfully.\")\n",
    "        return True\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to download the zip file from {zip_url}. Error: {e}\")\n",
    "        return False\n",
    "    except zipfile.BadZipFile as e:\n",
    "        print(f\"Failed to extract the zip file. Error: {e}\")\n",
    "        return False\n",
    "\n",
    "# Usage example:\n",
    "zip_url = 'http://www2.informatik.uni-freiburg.de/~cziegler/BX/BX-CSV-Dump.zip'\n",
    "target_directory = 'data/raw/'\n",
    "success = download_and_extract_zip(zip_url, target_directory)\n",
    "\n",
    "if success:\n",
    "    print(f\"Files have been extracted to '{target_directory}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.download_data import DownloadData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = DownloadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully: data/raw/goodreads/books.csv\n",
      "File downloaded successfully: data/raw/goodreads/ratings.csv\n"
     ]
    }
   ],
   "source": [
    "dd.download_goodreads_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zip download and extraction completed successfully: data/raw/bookcrossing/\n"
     ]
    }
   ],
   "source": [
    "dd.download_bookcrossing_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved to data/processed/book_reference_dataframe.pkl\n"
     ]
    }
   ],
   "source": [
    "from scripts.process_data import ProcessData\n",
    "import pandas as pd\n",
    "processor = ProcessData()\n",
    "final_dataframe = processor.get_final_dataframe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import zipfile\n",
    "import time\n",
    "import pickle \n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def map_columns_to_int(df: pd.DataFrame, save_column_name: list, mapping_dir: str = None):\n",
    "    \"\"\"\n",
    "    Map columns of strings in a DataFrame to integers.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing the columns to be mapped.\n",
    "        column_names (list): List of column names to be mapped.\n",
    "        mapping_dir (str): Directory path to save the mapping dictionaries. If None, mappings won't be saved.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with the mapped columns.\n",
    "    \"\"\"\n",
    "    for column_name in df.columns:\n",
    "        # Create a mapping dictionary that assigns a unique integer to each unique string in the column\n",
    "        unique_values = df[column_name].unique()\n",
    "        mapping_dict = {value: idx for idx, value in enumerate(unique_values)}\n",
    "\n",
    "        # Replace the strings in the column with their corresponding integer values\n",
    "        df[f\"{column_name}\"] = df[column_name].map(mapping_dict)\n",
    "\n",
    "        # Save the mapping dictionary to a file if mapping_dir is provided\n",
    "        if column_name == save_column_name:\n",
    "            mapping_file_path = f\"{mapping_dir}{column_name}_mapping.pkl\"\n",
    "            with open(mapping_file_path, 'wb') as f:\n",
    "                pickle.dump(mapping_dict, f)\n",
    "            print(f\"Mapping for column '{column_name}' saved to {mapping_file_path}\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping for column 'isbn_gr' saved to data/processed/isbn_gr_mapping.pkl\n"
     ]
    }
   ],
   "source": [
    "# Call the function to map the 'Fruit' column and save the mapping\n",
    "mapping_file_path = 'fruit_mapping.pkl'\n",
    "df_mapped = map_columns_to_int(final_dataframe, save_column_name='isbn_gr', mapping_dir='data/processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_gr</th>\n",
       "      <th>rating_gr</th>\n",
       "      <th>books_count_gr</th>\n",
       "      <th>isbn_gr</th>\n",
       "      <th>average_rating_gr</th>\n",
       "      <th>ratings_count_gr</th>\n",
       "      <th>work_ratings_count_gr</th>\n",
       "      <th>work_text_reviews_count_gr</th>\n",
       "      <th>ratings_1_gr</th>\n",
       "      <th>ratings_2_gr</th>\n",
       "      <th>ratings_3_gr</th>\n",
       "      <th>ratings_4_gr</th>\n",
       "      <th>ratings_5_gr</th>\n",
       "      <th>Book-Rating_bx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17750</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25293</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29017</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38052</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id_gr  rating_gr  books_count_gr  isbn_gr  average_rating_gr  \\\n",
       "0               0          0               0        0                  0   \n",
       "17750           0          0               1        1                  1   \n",
       "25293           0          1               2        2                  2   \n",
       "29017           0          0               3        3                  3   \n",
       "38052           0          0               4        4                  4   \n",
       "\n",
       "       ratings_count_gr  work_ratings_count_gr  work_text_reviews_count_gr  \\\n",
       "0                     0                      0                           0   \n",
       "17750                 1                      1                           1   \n",
       "25293                 2                      2                           2   \n",
       "29017                 3                      3                           3   \n",
       "38052                 4                      4                           4   \n",
       "\n",
       "       ratings_1_gr  ratings_2_gr  ratings_3_gr  ratings_4_gr  ratings_5_gr  \\\n",
       "0                 0             0             0             0             0   \n",
       "17750             1             1             1             1             1   \n",
       "25293             2             2             2             2             2   \n",
       "29017             3             3             3             3             3   \n",
       "38052             4             4             4             4             4   \n",
       "\n",
       "       Book-Rating_bx  \n",
       "0                   0  \n",
       "17750               1  \n",
       "25293               2  \n",
       "29017               3  \n",
       "38052               4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mapped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list = df_mapped.columns.tolist()\n",
    "y_columns = ['rating_gr']\n",
    "x_columns = [col for col in columns_list if col not in y_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_mapped.loc[:,y_columns]\n",
    "X = df_mapped.loc[:,x_columns]\n",
    "\n",
    "# Split our data into training and test sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y,random_state=0, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_dataloaders(X_train,y_train,X_val,y_val,batch_size):\n",
    "    # Convert training and test data to TensorDatasets\n",
    "    trainset = TensorDataset(torch.from_numpy(np.array(X_train)).long(), \n",
    "                            torch.from_numpy(np.array(y_train)).float())\n",
    "    valset = TensorDataset(torch.from_numpy(np.array(X_val)).long(), \n",
    "                            torch.from_numpy(np.array(y_val)).float())\n",
    "\n",
    "    # Create Dataloaders for our training and test data to allow us to iterate over minibatches \n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return trainloader, valloader\n",
    "\n",
    "batchsize = 64\n",
    "trainloader,valloader = prep_dataloaders(X_train,y_train,X_val,y_val,batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             0\n",
       "17750         0\n",
       "25293         0\n",
       "29017         0\n",
       "38052         0\n",
       "          ...  \n",
       "59977     49684\n",
       "154513    49684\n",
       "222792    49684\n",
       "262957    49685\n",
       "59978     49685\n",
       "Name: user_id_gr, Length: 264108, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['user_id_gr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\19105\\Documents\\githubPersonal\\Book-Recommendation-System\\main.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/19105/Documents/githubPersonal/Book-Recommendation-System/main.ipynb#Y152sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m np\u001b[39m.\u001b[39;49marray(X[\u001b[39m'\u001b[39;49m\u001b[39muser_id_gr\u001b[39;49m\u001b[39m'\u001b[39;49m])[:,\u001b[39m0\u001b[39;49m]\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "np.array(X['user_id_gr'])[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NNHybridFiltering(nn.Module):\n",
    "    def __init__(self, n_users, n_isbn, n_bookscount, n_avgratings, n_ratings, \n",
    "                 n_workratings, n_textratings, n_ratings1, n_ratings2, n_ratings3,\n",
    "                 n_ratings4, n_ratings5, n_bxrating, embdim_users, embdim_isbn, \n",
    "                 embdim_bookscount, embdim_avgratings, embdim_ratings, embdim_workratings,\n",
    "                 embdim_textratings, embdim_ratings1, embdim_ratings2, embdim_ratings3,\n",
    "                 embdim_ratings4, embdim_ratings5, embdim_bxrating, n_activations,\n",
    "                 rating_range):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.user_embeddings = nn.Embedding(num_embeddings=n_users, embedding_dim=embdim_users)\n",
    "        self.isbn_embeddings = nn.Embedding(num_embeddings=n_isbn, embedding_dim=embdim_isbn)\n",
    "        self.bookscount_embeddings = nn.Embedding(num_embeddings=n_bookscount, embedding_dim=embdim_bookscount)\n",
    "        self.avgratings_embeddings = nn.Embedding(num_embeddings=n_avgratings, embedding_dim=embdim_avgratings)\n",
    "        self.ratings_embeddings = nn.Embedding(num_embeddings=n_ratings, embedding_dim=embdim_ratings)\n",
    "        self.workratings_embeddings = nn.Embedding(num_embeddings=n_workratings, embedding_dim=embdim_workratings)\n",
    "        self.textratings_embeddings = nn.Embedding(num_embeddings=n_textratings, embedding_dim=embdim_textratings)\n",
    "        self.ratings1_embeddings = nn.Embedding(num_embeddings=n_ratings1, embedding_dim=embdim_ratings1)\n",
    "        self.ratings2_embeddings = nn.Embedding(num_embeddings=n_ratings2, embedding_dim=embdim_ratings2)\n",
    "        self.ratings3_embeddings = nn.Embedding(num_embeddings=n_ratings3, embedding_dim=embdim_ratings3)\n",
    "        self.ratings4_embeddings = nn.Embedding(num_embeddings=n_ratings4, embedding_dim=embdim_ratings4)\n",
    "        self.ratings5_embeddings = nn.Embedding(num_embeddings=n_ratings5, embedding_dim=embdim_ratings5)\n",
    "        self.bxrating_embeddings = nn.Embedding(num_embeddings=n_bxrating, embedding_dim=embdim_bxrating)\n",
    "\n",
    "        embdim_sum = (\n",
    "            embdim_users + embdim_isbn + embdim_bookscount + embdim_avgratings +\n",
    "            embdim_ratings + embdim_workratings + embdim_textratings +\n",
    "            embdim_ratings1 + embdim_ratings2 + embdim_ratings3 +\n",
    "            embdim_ratings4 + embdim_ratings5 + embdim_bxrating\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(embdim_sum, n_activations)\n",
    "        self.fc2 = nn.Linear(n_activations, 1)\n",
    "        self.rating_range = rating_range\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Get embeddings for minibatch\n",
    "        embedded_users = self.user_embeddings(X['user_id_gr'])\n",
    "        embedded_isbn = self.isbn_embeddings(X['isbn_gr'])\n",
    "        embedded_bookscount = self.bookscount_embeddings(X['books_count_gr'])\n",
    "        embedded_avgratings = self.avgratings_embeddings(X['average_rating_gr'])\n",
    "        embedded_ratings = self.ratings_embeddingsy(X['ratings_count_gr'])\n",
    "        embedded_workratings = self.workratings_embeddings(X['work_ratings_count_gr'])\n",
    "        embedded_textratings = self.textratings_embeddings(X['work_text_reviews_count_gr'] )\n",
    "        embedded_ratings1 = self.ratings1_embeddings(X['ratings_1_gr'])\n",
    "        embedded_ratings2 = self.ratings1_embeddings(X['ratings_2_gr'])\n",
    "        embedded_ratings3 = self.ratings3_embeddings(X['ratings_3_gr'])\n",
    "        embedded_ratings4 = self.ratings4_embeddings(X['ratings_4_gr'])\n",
    "        embedded_ratings5 = self.ratings5_embeddings(X['ratings_5_gr'])\n",
    "        embedded_bxrating = self.bxrating_embeddings(X['Book-Rating_bx'])\n",
    "\n",
    "        # Concatenate user, item and genre embeddings\n",
    "        embeddings = torch.cat([embedded_users, embedded_isbn, embedded_bookscount, \n",
    "                                embedded_avgratings, embedded_ratings, embedded_workratings,\n",
    "                                embedded_textratings, embedded_ratings1, embedded_ratings2,\n",
    "                                embedded_ratings3, embedded_ratings4, embedded_ratings5, embedded_bxrating\n",
    "                                ], dim=1)\n",
    "\n",
    "        # Pass embeddings through network\n",
    "        preds = self.fc1(embeddings)\n",
    "        preds = F.relu(preds)\n",
    "        preds = self.fc2(preds)\n",
    "        # Scale predicted ratings to target-range [low, high]\n",
    "        preds = torch.sigmoid(preds) * (self.rating_range[1] - self.rating_range[0]) + self.rating_range[0]\n",
    "        return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0, ..., 49684, 49685, 49685], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X['user_id_gr']).reshape(-1,1)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, dataloaders, device, num_epochs=5, scheduler=None):\n",
    "    model = model.to(device) # Send model to GPU if available\n",
    "    since = time.time()\n",
    "\n",
    "    costpaths = {'train':[],'val':[]}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "            # Get the inputs and labels, and send to GPU if available\n",
    "            for (inputs,labels) in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Zero the weight gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass to get outputs and calculate loss\n",
    "                # Track gradient only for training data\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model.forward(inputs).view(-1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backpropagation to get the gradients with respect to each weight\n",
    "                    # Only if in train\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        # Update the weights\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Convert loss into a scalar and add it to running_loss\n",
    "                running_loss += np.sqrt(loss.item()) * labels.size(0)\n",
    "\n",
    "            # Step along learning rate scheduler when in train\n",
    "            if (phase == 'train') and (scheduler is not None):\n",
    "                scheduler.step()\n",
    "\n",
    "            # Calculate and display average loss and accuracy for the epoch\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            costpaths[phase].append(epoch_loss)\n",
    "            print('{} loss: {:.4f}'.format(phase, epoch_loss))\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    return costpaths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\19105\\Documents\\githubPersonal\\Book-Recommendation-System\\main.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 68>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/19105/Documents/githubPersonal/Book-Recommendation-System/main.ipynb#Y140sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlr, weight_decay\u001b[39m=\u001b[39mwd)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/19105/Documents/githubPersonal/Book-Recommendation-System/main.ipynb#Y140sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/19105/Documents/githubPersonal/Book-Recommendation-System/main.ipynb#Y140sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m cost_paths \u001b[39m=\u001b[39m train_model(model,criterion,optimizer,dataloaders, device,n_epochs, scheduler\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n",
      "\u001b[1;32mc:\\Users\\19105\\Documents\\githubPersonal\\Book-Recommendation-System\\main.ipynb Cell 20\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, criterion, optimizer, dataloaders, device, num_epochs, scheduler)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/19105/Documents/githubPersonal/Book-Recommendation-System/main.ipynb#Y140sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Forward pass to get outputs and calculate loss\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/19105/Documents/githubPersonal/Book-Recommendation-System/main.ipynb#Y140sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# Track gradient only for training data\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/19105/Documents/githubPersonal/Book-Recommendation-System/main.ipynb#Y140sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mset_grad_enabled(phase \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/19105/Documents/githubPersonal/Book-Recommendation-System/main.ipynb#Y140sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mforward(inputs)\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/19105/Documents/githubPersonal/Book-Recommendation-System/main.ipynb#Y140sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/19105/Documents/githubPersonal/Book-Recommendation-System/main.ipynb#Y140sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39m# Backpropagation to get the gradients with respect to each weight\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/19105/Documents/githubPersonal/Book-Recommendation-System/main.ipynb#Y140sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     \u001b[39m# Only if in train\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\19105\\Documents\\githubPersonal\\Book-Recommendation-System\\main.ipynb Cell 20\u001b[0m in \u001b[0;36mNNHybridFiltering.forward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/19105/Documents/githubPersonal/Book-Recommendation-System/main.ipynb#Y140sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/19105/Documents/githubPersonal/Book-Recommendation-System/main.ipynb#Y140sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     \u001b[39m# Get embeddings for minibatch\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/19105/Documents/githubPersonal/Book-Recommendation-System/main.ipynb#Y140sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     embedded_users \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_embeddings(X[\u001b[39m'\u001b[39;49m\u001b[39muser_id_gr\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/19105/Documents/githubPersonal/Book-Recommendation-System/main.ipynb#Y140sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     embedded_isbn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39misbn_embeddings(X[\u001b[39m'\u001b[39m\u001b[39misbn_gr\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/19105/Documents/githubPersonal/Book-Recommendation-System/main.ipynb#Y140sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     embedded_bookscount \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbookscount_embeddings(X[\u001b[39m'\u001b[39m\u001b[39mbooks_count_gr\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "dataloaders = {'train':trainloader, 'val':valloader}\n",
    "n_users = X.loc[:,'user_id_gr'].max() + 1\n",
    "n_isbn = X.loc[:,'isbn_gr'].max() + 1\n",
    "n_bookscount = X.loc[:,'books_count_gr'].max() + 1\n",
    "n_avgratings = X.loc[:,'average_rating_gr'].max() + 1\n",
    "n_ratings = X.loc[:,'ratings_count_gr'].max() + 1\n",
    "n_workratings = X.loc[:,'work_ratings_count_gr'].max() + 1\n",
    "n_textratings = X.loc[:,'work_text_reviews_count_gr'].max() + 1\n",
    "n_ratings1 = X.loc[:,'ratings_1_gr'].max() + 1\n",
    "n_ratings2 = X.loc[:,'ratings_2_gr'].max() + 1\n",
    "n_ratings3 = X.loc[:,'ratings_3_gr'].max() + 1\n",
    "n_ratings4 = X.loc[:,'ratings_4_gr'].max() + 1\n",
    "n_ratings5 = X.loc[:,'ratings_5_gr'].max() + 1\n",
    "n_bxrating = X.loc[:,'Book-Rating_bx'].max() + 1\n",
    "\n",
    "embdim_users = 50\n",
    "embdim_isbn = 50\n",
    "embdim_bookscount = 50\n",
    "embdim_avgratings = 50\n",
    "embdim_ratings = 50\n",
    "embdim_workratings = 50\n",
    "embdim_textratings = 50\n",
    "embdim_ratings1 = 50\n",
    "embdim_ratings2 = 50\n",
    "embdim_ratings3 = 50\n",
    "embdim_ratings4 = 50\n",
    "embdim_ratings5 = 50\n",
    "embdim_bxrating = 50\n",
    "\n",
    "model = NNHybridFiltering(                \n",
    "                        n_users = n_users,\n",
    "                        n_isbn = n_isbn, \n",
    "                        n_bookscount = n_bookscount,\n",
    "                        n_avgratings = n_avgratings,\n",
    "                        n_ratings = n_ratings, \n",
    "                        n_workratings = n_workratings, \n",
    "                        n_textratings = n_textratings,\n",
    "                        n_ratings1 = n_ratings1, \n",
    "                        n_ratings2 = n_ratings2, \n",
    "                        n_ratings3 = n_ratings3, \n",
    "                        n_ratings4 = n_ratings4, \n",
    "                        n_ratings5 = n_ratings5, \n",
    "                        n_bxrating = n_bxrating,\n",
    "                        embdim_users = embdim_users,\n",
    "                        embdim_isbn = embdim_isbn, \n",
    "                        embdim_bookscount = embdim_bookscount,\n",
    "                        embdim_avgratings = embdim_avgratings, \n",
    "                        embdim_ratings = embdim_ratings,\n",
    "                        embdim_workratings = embdim_workratings,\n",
    "                        embdim_textratings = embdim_textratings,\n",
    "                        embdim_ratings1 = embdim_ratings1,\n",
    "                        embdim_ratings2 = embdim_ratings2, \n",
    "                        embdim_ratings3 = embdim_ratings3, \n",
    "                        embdim_ratings4 = embdim_ratings4, \n",
    "                        embdim_ratings5 = embdim_ratings5, \n",
    "                        embdim_bxrating = embdim_bxrating,\n",
    "                        n_activations= 100,\n",
    "                        rating_range=[0.,4.])\n",
    "                       \n",
    "criterion = nn.MSELoss()\n",
    "lr=0.001\n",
    "n_epochs=10\n",
    "wd=1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "cost_paths = train_model(model,criterion,optimizer,dataloaders, device,n_epochs, scheduler=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             0\n",
       "17750         0\n",
       "25293         0\n",
       "29017         0\n",
       "38052         0\n",
       "          ...  \n",
       "59977     49684\n",
       "154513    49684\n",
       "222792    49684\n",
       "262957    49685\n",
       "59978     49685\n",
       "Name: user_id_gr, Length: 264108, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['user_id_gr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
