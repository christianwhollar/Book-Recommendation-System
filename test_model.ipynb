{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved to data/processed/book_reference_dataframe.pkl\n"
     ]
    }
   ],
   "source": [
    "from scripts.process_data import ProcessData\n",
    "processor = ProcessData()\n",
    "final_dataframe = processor.get_final_dataframe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import zipfile\n",
    "import time\n",
    "import pickle \n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def map_columns_to_int(df: pd.DataFrame, save_column_name: list, mapping_dir: str = None):\n",
    "    \"\"\"\n",
    "    Map columns of strings in a DataFrame to integers.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing the columns to be mapped.\n",
    "        column_names (list): List of column names to be mapped.\n",
    "        mapping_dir (str): Directory path to save the mapping dictionaries. If None, mappings won't be saved.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with the mapped columns.\n",
    "    \"\"\"\n",
    "    for column_name in df.columns:\n",
    "        # Create a mapping dictionary that assigns a unique integer to each unique string in the column\n",
    "        unique_values = df[column_name].unique()\n",
    "        mapping_dict = {value: idx for idx, value in enumerate(unique_values)}\n",
    "\n",
    "        # Replace the strings in the column with their corresponding integer values\n",
    "        df[f\"{column_name}\"] = df[column_name].map(mapping_dict)\n",
    "\n",
    "        # Save the mapping dictionary to a file if mapping_dir is provided\n",
    "        if column_name == save_column_name:\n",
    "            mapping_file_path = f\"{mapping_dir}{column_name}_mapping.pkl\"\n",
    "            with open(mapping_file_path, 'wb') as f:\n",
    "                pickle.dump(mapping_dict, f)\n",
    "            print(f\"Mapping for column '{column_name}' saved to {mapping_file_path}\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping for column 'isbn_gr' saved to data/processed/isbn_gr_mapping.pkl\n"
     ]
    }
   ],
   "source": [
    "# Call the function to map the 'Fruit' column and save the mapping\n",
    "mapping_file_path = 'fruit_mapping.pkl'\n",
    "df_mapped = map_columns_to_int(final_dataframe, save_column_name='isbn_gr', mapping_dir='data/processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_gr</th>\n",
       "      <th>rating_gr</th>\n",
       "      <th>books_count_gr</th>\n",
       "      <th>isbn_gr</th>\n",
       "      <th>average_rating_gr</th>\n",
       "      <th>ratings_count_gr</th>\n",
       "      <th>work_ratings_count_gr</th>\n",
       "      <th>work_text_reviews_count_gr</th>\n",
       "      <th>ratings_1_gr</th>\n",
       "      <th>ratings_2_gr</th>\n",
       "      <th>ratings_3_gr</th>\n",
       "      <th>ratings_4_gr</th>\n",
       "      <th>ratings_5_gr</th>\n",
       "      <th>rating_bx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17750</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25293</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29017</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38052</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id_gr  rating_gr  books_count_gr  isbn_gr  average_rating_gr  \\\n",
       "0               0          0               0        0                  0   \n",
       "17750           0          0               1        1                  1   \n",
       "25293           0          1               2        2                  2   \n",
       "29017           0          0               3        3                  3   \n",
       "38052           0          0               4        4                  4   \n",
       "\n",
       "       ratings_count_gr  work_ratings_count_gr  work_text_reviews_count_gr  \\\n",
       "0                     0                      0                           0   \n",
       "17750                 1                      1                           1   \n",
       "25293                 2                      2                           2   \n",
       "29017                 3                      3                           3   \n",
       "38052                 4                      4                           4   \n",
       "\n",
       "       ratings_1_gr  ratings_2_gr  ratings_3_gr  ratings_4_gr  ratings_5_gr  \\\n",
       "0                 0             0             0             0             0   \n",
       "17750             1             1             1             1             1   \n",
       "25293             2             2             2             2             2   \n",
       "29017             3             3             3             3             3   \n",
       "38052             4             4             4             4             4   \n",
       "\n",
       "       rating_bx  \n",
       "0              0  \n",
       "17750          1  \n",
       "25293          2  \n",
       "29017          3  \n",
       "38052          4  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mapped.rename(columns={'Book-Rating_bx':'rating_bx'}, inplace=True)\n",
    "df_mapped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating_gr    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_mapped.loc[:, ['user_id_gr', 'isbn_gr','rating_bx']]\n",
    "y = df_mapped.loc[:, ['rating_gr']]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y,random_state=0, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_dataloaders(X_train,y_train,X_val,y_val,batch_size):\n",
    "    # Convert training and test data to TensorDatasets\n",
    "    trainset = TensorDataset(torch.from_numpy(np.array(X_train)).long(), \n",
    "                            torch.from_numpy(np.array(y_train)).float())\n",
    "    valset = TensorDataset(torch.from_numpy(np.array(X_val)).long(), \n",
    "                            torch.from_numpy(np.array(y_val)).float())\n",
    "\n",
    "    # Create Dataloaders for our training and test data to allow us to iterate over minibatches \n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return trainloader, valloader\n",
    "\n",
    "batchsize = 128\n",
    "trainloader,valloader = prep_dataloaders(X_train,y_train,X_val,y_val,batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNHybridFiltering(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_users, n_isbn, n_bxrating, embdim_users, embdim_isbn, embdim_bxrating, n_activations, rating_range):\n",
    "        super().__init__()\n",
    "        self.user_embeddings = nn.Embedding(num_embeddings=n_users,embedding_dim=embdim_users)\n",
    "        self.item_embeddings = nn.Embedding(num_embeddings=n_isbn,embedding_dim=embdim_isbn)\n",
    "        self.genre_embeddings = nn.Embedding(num_embeddings=n_bxrating,embedding_dim=embdim_bxrating)\n",
    "        self.fc1 = nn.Linear(embdim_users+embdim_isbn+embdim_bxrating,n_activations)\n",
    "        self.fc2 = nn.Linear(n_activations,1)\n",
    "        self.rating_range = rating_range\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Get embeddings for minibatch\n",
    "        embedded_users = self.user_embeddings(X[:,0])\n",
    "        embedded_isbn = self.item_embeddings(X[:,1])\n",
    "        embedded_bxrating = self.genre_embeddings(X[:,2])\n",
    "        # Concatenate user, item and genre embeddings\n",
    "        embeddings = torch.cat([embedded_users,embedded_isbn,embedded_bxrating],dim=1)\n",
    "        # Pass embeddings through network\n",
    "        preds = self.fc1(embeddings)\n",
    "        preds = F.relu(preds)\n",
    "        preds = self.fc2(preds)\n",
    "        # Scale predicted ratings to target-range [low,high]\n",
    "        preds = torch.sigmoid(preds) * (self.rating_range[1]-self.rating_range[0]) + self.rating_range[0]\n",
    "        return preds\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, dataloaders, device, num_epochs=5, scheduler=None):\n",
    "    model = model.to(device) # Send model to GPU if available\n",
    "    since = time.time()\n",
    "\n",
    "    costpaths = {'train':[],'val':[]}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "            # Get the inputs and labels, and send to GPU if available\n",
    "            for (inputs,labels) in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                labels = labels.squeeze(1)\n",
    "                # Zero the weight gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass to get outputs and calculate loss\n",
    "                # Track gradient only for training data\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model.forward(inputs).view(-1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backpropagation to get the gradients with respect to each weight\n",
    "                    # Only if in train\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        # Update the weights\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Convert loss into a scalar and add it to running_loss\n",
    "                running_loss += np.sqrt(loss.item()) * labels.size(0)\n",
    "\n",
    "            # Step along learning rate scheduler when in train\n",
    "            if (phase == 'train') and (scheduler is not None):\n",
    "                scheduler.step()\n",
    "\n",
    "            # Calculate and display average loss and accuracy for the epoch\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            costpaths[phase].append(epoch_loss)\n",
    "            print('{} loss: {:.4f}'.format(phase, epoch_loss))\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    return costpaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train loss: 1.1392\n",
      "val loss: 1.1352\n",
      "Epoch 1/9\n",
      "----------\n",
      "train loss: 1.1328\n",
      "val loss: 1.1326\n",
      "Epoch 2/9\n",
      "----------\n",
      "train loss: 1.1188\n",
      "val loss: 1.1064\n",
      "Epoch 3/9\n",
      "----------\n",
      "train loss: 1.0769\n",
      "val loss: 1.0913\n",
      "Epoch 4/9\n",
      "----------\n",
      "train loss: 1.0350\n",
      "val loss: 1.0913\n",
      "Epoch 5/9\n",
      "----------\n",
      "train loss: 1.0121\n",
      "val loss: 1.0936\n",
      "Epoch 6/9\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\19105\\Documents\\githubPersonal\\Book-Recommendation-System\\test_model.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/19105/Documents/githubPersonal/Book-Recommendation-System/test_model.ipynb#X11sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlr, weight_decay\u001b[39m=\u001b[39mwd)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/19105/Documents/githubPersonal/Book-Recommendation-System/test_model.ipynb#X11sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/19105/Documents/githubPersonal/Book-Recommendation-System/test_model.ipynb#X11sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m cost_paths \u001b[39m=\u001b[39m train_model(model,criterion,optimizer,dataloaders, device,n_epochs, scheduler\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n",
      "\u001b[1;32mc:\\Users\\19105\\Documents\\githubPersonal\\Book-Recommendation-System\\test_model.ipynb Cell 10\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, criterion, optimizer, dataloaders, device, num_epochs, scheduler)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/19105/Documents/githubPersonal/Book-Recommendation-System/test_model.ipynb#X11sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# Backpropagation to get the gradients with respect to each weight\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/19105/Documents/githubPersonal/Book-Recommendation-System/test_model.ipynb#X11sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# Only if in train\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/19105/Documents/githubPersonal/Book-Recommendation-System/test_model.ipynb#X11sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mif\u001b[39;00m phase \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/19105/Documents/githubPersonal/Book-Recommendation-System/test_model.ipynb#X11sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/19105/Documents/githubPersonal/Book-Recommendation-System/test_model.ipynb#X11sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     \u001b[39m# Update the weights\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/19105/Documents/githubPersonal/Book-Recommendation-System/test_model.ipynb#X11sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\19105\\anaconda3\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\19105\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "dataloaders = {'train':trainloader, 'val':valloader}\n",
    "\n",
    "n_users = X.loc[:,'user_id_gr'].max()+1\n",
    "n_isbn = X.loc[:,'isbn_gr'].max()+1\n",
    "n_bxrating = X.loc[:,'rating_bx'].max()+1\n",
    "\n",
    "model = NNHybridFiltering(n_users,\n",
    "                       n_isbn,\n",
    "                       n_bxrating,\n",
    "                       embdim_users=50, \n",
    "                       embdim_isbn=50, \n",
    "                       embdim_bxrating=25,\n",
    "                       n_activations = 100,\n",
    "                       rating_range=[0.,4.])\n",
    "criterion = nn.MSELoss()\n",
    "lr=0.001\n",
    "n_epochs=10\n",
    "wd=1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "cost_paths = train_model(model,criterion,optimizer,dataloaders, device,n_epochs, scheduler=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
